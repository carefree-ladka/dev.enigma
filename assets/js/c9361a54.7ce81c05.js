"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[6821],{9472:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>c,toc:()=>l});var n=t(4848),s=t(8453);const i={},a="Async Patterns",c={id:"WebDev/JavaScript/AsyncPatterns",title:"Async Patterns",description:"Rate Limiter",source:"@site/docs/WebDev/JavaScript/AsyncPatterns.mdx",sourceDirName:"WebDev/JavaScript",slug:"/WebDev/JavaScript/AsyncPatterns",permalink:"/js.enigma/docs/WebDev/JavaScript/AsyncPatterns",draft:!1,unlisted:!1,editUrl:"https://github.com/carefree-ladka/docs/WebDev/JavaScript/AsyncPatterns.mdx",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Async Await",permalink:"/js.enigma/docs/WebDev/JavaScript/AsyncAwait"},next:{title:"Closures",permalink:"/js.enigma/docs/WebDev/JavaScript/Closure"}},o={},l=[{value:"Rate Limiter",id:"rate-limiter",level:2},{value:"Circuit Breaker",id:"circuit-breaker",level:2},{value:"Batch Processing",id:"batch-processing",level:2},{value:"With Concurrency Control",id:"with-concurrency-control",level:2},{value:"Retry Pattern",id:"retry-pattern",level:2},{value:"Sequential Batching",id:"sequential-batching",level:2}];function u(e){const r={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(r.header,{children:(0,n.jsx)(r.h1,{id:"async-patterns",children:"Async Patterns"})}),"\n",(0,n.jsx)(r.h2,{id:"rate-limiter",children:"Rate Limiter"}),"\n",(0,n.jsx)(r.p,{children:"A rate limiter is a mechanism used to control the number of requests a client can make to a server within a specified time period. This is useful for preventing abuse, ensuring fair usage, and protecting against denial-of-service (DoS) attacks."}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-JavaScript",children:"class RateLimiter {\r\n  constructor(maxRequests, windowSizeInMs) {\r\n    this.maxRequests = maxRequests; // Maximum number of requests allowed in the window\r\n    this.windowSizeInMs = windowSizeInMs; // Time window size in milliseconds\r\n    this.requests = []; // Array to store timestamps of requests\r\n  }\r\n\r\n  // Method to check if a request is allowed\r\n  allowRequest() {\r\n    const now = Date.now();\r\n\r\n    // Remove requests that are outside the current window\r\n    this.requests = this.requests.filter(timestamp => now - timestamp < this.windowSizeInMs);\r\n\r\n    // Check if the number of requests is within the limit\r\n    if (this.requests.length < this.maxRequests) {\r\n      this.requests.push(now); // Add the current request timestamp\r\n      return true; // Request is allowed\r\n    } else {\r\n      return false; // Request is denied\r\n    }\r\n  }\r\n}\r\n\r\n// Example usage\r\nconst limiter = new RateLimiter(5, 10000); // Allow 5 requests per 10 seconds\r\n\r\nfor (let i = 0; i < 10; i++) {\r\n  setTimeout(() => {\r\n    if (limiter.allowRequest()) {\r\n      console.log(`Request ${i + 1}: Allowed`);\r\n    } else {\r\n      console.log(`Request ${i + 1}: Denied`);\r\n    }\r\n  }, i * 1000); // Simulate requests every second\r\n}\n"})}),"\n",(0,n.jsx)(r.h2,{id:"circuit-breaker",children:"Circuit Breaker"}),"\n",(0,n.jsx)(r.p,{children:"A circuit breaker is a design pattern used to detect failures and prevent an application from repeatedly trying to execute an operation that's likely to fail. It\u2019s commonly used in distributed systems to handle faults gracefully and avoid cascading failures."}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-JavaScript",children:'class CircuitBreaker {\r\n    constructor(request, options = {}) {\r\n        this.request = request; // The function to be executed\r\n        this.state = "CLOSED"; // Initial state: CLOSED, OPEN, or HALF-OPEN\r\n        this.failureCount = 0; // Count of consecutive failures\r\n        this.successCount = 0; // Count of consecutive successes (for HALF-OPEN state)\r\n        this.nextAttempt = Date.now(); // Time for the next attempt in OPEN state\r\n        this.options = {\r\n            failureThreshold: 3, // Number of failures before opening the circuit\r\n            successThreshold: 2, // Number of successes before closing the circuit\r\n            timeout: 5000, // Time in ms to wait before attempting again in OPEN state\r\n            ...options,\r\n        };\r\n    }\r\n\r\n    async fire() {\r\n        if (this.state === "OPEN") {\r\n            if (this.nextAttempt <= Date.now()) {\r\n                this.state = "HALF-OPEN"; // Allow one request to test the service\r\n            } else {\r\n                throw new Error("Circuit is OPEN. Request blocked.");\r\n            }\r\n        }\r\n\r\n        try {\r\n            const response = await this.request();\r\n            this.success();\r\n            return response;\r\n        } catch (err) {\r\n            this.fail();\r\n            throw err;\r\n        }\r\n    }\r\n\r\n    success() {\r\n        this.failureCount = 0; // Reset failure count\r\n        if (this.state === "HALF-OPEN") {\r\n            this.successCount++;\r\n            if (this.successCount >= this.options.successThreshold) {\r\n                this.state = "CLOSED"; // Close the circuit after enough successes\r\n            }\r\n        }\r\n    }\r\n\r\n    fail() {\r\n        this.failureCount++;\r\n        if (this.failureCount >= this.options.failureThreshold) {\r\n            this.state = "OPEN"; // Open the circuit after too many failures\r\n            this.nextAttempt = Date.now() + this.options.timeout;\r\n        }\r\n    }\r\n}\r\n\r\n// Example usage\r\nconst unstableRequest = () => {\r\n    return new Promise((resolve, reject) => {\r\n        // Simulate a 50% chance of failure\r\n        if (Math.random() > 0.5) {\r\n            resolve("Success!");\r\n        } else {\r\n            reject("Failed!");\r\n        }\r\n    });\r\n};\r\n\r\nconst breaker = new CircuitBreaker(unstableRequest, {\r\n    failureThreshold: 2,\r\n    successThreshold: 1,\r\n    timeout: 1000,\r\n});\r\n\r\nconst testCircuitBreaker = async () => {\r\n    for (let i = 0; i < 10; i++) {\r\n        try {\r\n            const result = await breaker.fire();\r\n            console.log(`Request ${i + 1}: ${result}`);\r\n        } catch (err) {\r\n            console.log(`Request ${i + 1}: ${err}`);\r\n        }\r\n        await new Promise((resolve) => setTimeout(resolve, 500)); // Delay between requests\r\n    }\r\n};\r\n\r\ntestCircuitBreaker();\n'})}),"\n",(0,n.jsx)(r.h2,{id:"batch-processing",children:"Batch Processing"}),"\n",(0,n.jsx)(r.p,{children:"Batching promises is a technique used to group multiple asynchronous operations (promises) into a single batch to improve efficiency, reduce overhead, and manage concurrency. This is particularly useful when dealing with APIs, databases, or other I/O-bound operations where making individual requests can be inefficient."}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-JavaScript",children:'class PromiseBatcher {\r\n    constructor(batchSize, processBatch) {\r\n        this.batchSize = batchSize; // Maximum number of promises in a batch\r\n        this.processBatch = processBatch; // Function to process the batch\r\n        this.queue = []; // Queue to hold pending items\r\n        this.processing = false; // Flag to check if a batch is being processed\r\n    }\r\n\r\n    // Add an item to the queue and trigger processing\r\n    add(item) {\r\n        this.queue.push(item);\r\n        this.process();\r\n    }\r\n\r\n    // Process the queue in batches\r\n    async process() {\r\n        if (this.processing || this.queue.length === 0) {\r\n            return; // Avoid overlapping processing\r\n        }\r\n\r\n        this.processing = true;\r\n\r\n        // Take up to `batchSize` items from the queue\r\n        const batch = this.queue.splice(0, this.batchSize);\r\n\r\n        try {\r\n            // Process the batch using the provided function\r\n            await this.processBatch(batch);\r\n        } catch (error) {\r\n            console.error("Error processing batch:", error);\r\n        } finally {\r\n            this.processing = false;\r\n            this.process(); // Process the next batch if there are remaining items\r\n        }\r\n    }\r\n}\r\n\r\n// Example usage\r\nconst batcher = new PromiseBatcher(3, async (batch) => {\r\n    console.log("Processing batch:", batch);\r\n    // Simulate an async operation (e.g., API call, database query)\r\n    await new Promise((resolve) => setTimeout(resolve, 1000));\r\n    console.log("Batch processed:", batch);\r\n});\r\n\r\n// Add items to the batcher\r\nfor (let i = 1; i <= 10; i++) {\r\n    batcher.add(i);\r\n}\n'})}),"\n",(0,n.jsx)(r.h2,{id:"with-concurrency-control",children:"With Concurrency Control"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-JavaScript",children:'class ConcurrentPromiseBatcher {\r\n    constructor(batchSize, concurrency, processBatch) {\r\n        this.batchSize = batchSize;\r\n        this.concurrency = concurrency;\r\n        this.processBatch = processBatch;\r\n        this.queue = [];\r\n        this.processing = 0;\r\n    }\r\n\r\n    add(item) {\r\n        this.queue.push(item);\r\n        this.process();\r\n    }\r\n\r\n    async process() {\r\n        while (this.queue.length > 0 && this.processing < this.concurrency) {\r\n            const batch = this.queue.splice(0, this.batchSize);\r\n            this.processing++;\r\n\r\n            this.processBatch(batch)\r\n                .catch((error) => console.error("Error processing batch:", error))\r\n                .finally(() => {\r\n                    this.processing--;\r\n                    this.process();\r\n                });\r\n        }\r\n    }\r\n}\r\n\r\n// Example usage\r\nconst concurrentBatcher = new ConcurrentPromiseBatcher(3, 2, async (batch) => {\r\n    console.log("Processing batch:", batch);\r\n    await new Promise((resolve) => setTimeout(resolve, 1000));\r\n    console.log("Batch processed:", batch);\r\n});\r\n\r\nfor (let i = 1; i <= 10; i++) {\r\n    concurrentBatcher.add(i);\r\n}\n'})}),"\n",(0,n.jsx)(r.h2,{id:"retry-pattern",children:"Retry Pattern"}),"\n",(0,n.jsx)(r.p,{children:"The Retry Pattern is a design pattern used to handle transient failures in an application by retrying a failed operation a specified number of times before giving up. This is particularly useful for operations that involve external systems, such as API calls, database queries, or network requests, where temporary issues (e.g., network latency, timeouts) can cause failures."}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-JavaScript",children:'const retry = async (fn, retries = 3, delay = 1000) => {\r\n  try {\r\n    return await fn();\r\n  } catch (error) {\r\n    if (retries <= 0) {\r\n      throw error; // No retries left\r\n    }\r\n    console.log(`Retrying... (${retries} retries left)`);\r\n    await new Promise(resolve => setTimeout(resolve, delay));\r\n    return retry(fn, retries - 1, delay); // Retry with reduced count\r\n  }\r\n};\r\n\r\n// Example Usage:\r\nconst fetchData = async () => {\r\n  // Simulate a failing network request\r\n  if (Math.random() < 0.7) throw new Error("Network error");\r\n  return "Data fetched successfully!";\r\n};\r\n\r\nretry(fetchData)\r\n  .then(data => console.log(data))\r\n  .catch(err => console.error(err));\n'})}),"\n",(0,n.jsx)(r.h2,{id:"sequential-batching",children:"Sequential Batching"}),"\n",(0,n.jsxs)(r.p,{children:["If you have a large number of tasks (such as API requests or computations) and want to execute them in batches sequentially\u2014meaning that each batch runs after the previous one completes\u2014you can achieve this using ",(0,n.jsx)(r.code,{children:"async/await"})," and ",(0,n.jsx)(r.code,{children:"for...of"})," loops."]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-JavaScript",children:"const sequentialBatch = async (tasks, batchSize = 5) => {\r\n  const results = [];\r\n  \r\n  for (let i = 0; i < tasks.length; i += batchSize) {\r\n    const batch = tasks.slice(i, i + batchSize);\r\n    const batchResults = await Promise.all(batch.map(task => task())); // Run batch concurrently\r\n    results.push(...batchResults);\r\n  }\r\n  \r\n  return results;\r\n};\r\n\r\n// Example Usage:\r\nconst tasks = Array.from({ length: 15 }, (_, index) => () =>\r\n  new Promise(resolve => setTimeout(() => resolve(`Task ${index + 1} done`), 500))\r\n);\r\n\r\nsequentialBatch(tasks, 5).then(results => console.log(results));\r\n\r\n/* \r\nIf you have 15 tasks and a batch size of 5, the execution would look like:\r\n\r\n1. First 5 tasks \u2192 Execute in parallel \u2192 Wait for them to finish.\r\n2. Next 5 tasks \u2192 Execute in parallel \u2192 Wait for them to finish.\r\n3. Last 5 tasks \u2192 Execute in parallel \u2192 Wait for them to finish.\r\n4. Return all results.\r\n*/\n"})})]})}function h(e={}){const{wrapper:r}={...(0,s.R)(),...e.components};return r?(0,n.jsx)(r,{...e,children:(0,n.jsx)(u,{...e})}):u(e)}},8453:(e,r,t)=>{t.d(r,{R:()=>a,x:()=>c});var n=t(6540);const s={},i=n.createContext(s);function a(e){const r=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function c(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),n.createElement(i.Provider,{value:r},e.children)}}}]);