"use strict";(self.webpackChunkdev_enigma=self.webpackChunkdev_enigma||[]).push([[14388],{28453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>l});var a=r(96540);const t={},s=a.createContext(t);function i(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),a.createElement(s.Provider,{value:n},e.children)}},41387:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>m,frontMatter:()=>s,metadata:()=>l,toc:()=>o});var a=r(74848),t=r(28453);const s={},i="How Programs Execute: CPU, RAM & Memory Management",l={id:"Java Interview Guide/How Programs Execute: CPU, RAM & Memory Management",title:"How Programs Execute: CPU, RAM & Memory Management",description:"Overview",source:"@site/docs/Java Interview Guide/How Programs Execute: CPU, RAM & Memory Management.mdx",sourceDirName:"Java Interview Guide",slug:"/Java Interview Guide/How Programs Execute: CPU, RAM & Memory Management",permalink:"/docs/Java Interview Guide/How Programs Execute: CPU, RAM & Memory Management",draft:!1,unlisted:!1,editUrl:"https://github.com/carefree-ladka/docs/Java Interview Guide/How Programs Execute: CPU, RAM & Memory Management.mdx",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Complete Java Star Patterns Guide",permalink:"/docs/Java Interview Guide/Complete Java Star Patterns Guide"},next:{title:"Java 8 Stream Practice Problems with Solutions",permalink:"/docs/Java Interview Guide/Java 8 Stream Practice Problems"}},c={},o=[{value:"Overview",id:"overview",level:2},{value:"Computer Architecture Fundamentals",id:"computer-architecture-fundamentals",level:2},{value:"CPU Architecture",id:"cpu-architecture",level:2},{value:"Inside the CPU",id:"inside-the-cpu",level:3},{value:"Key CPU Components",id:"key-cpu-components",level:3},{value:"Program Execution Flow",id:"program-execution-flow",level:2},{value:"From Storage to Execution",id:"from-storage-to-execution",level:3},{value:"Memory Hierarchy",id:"memory-hierarchy",level:2},{value:"CPU Instruction Cycle (Fetch-Decode-Execute)",id:"cpu-instruction-cycle-fetch-decode-execute",level:2},{value:"Example: Adding Two Numbers",id:"example-adding-two-numbers",level:3},{value:"RAM Organization for a Program",id:"ram-organization-for-a-program",level:2},{value:"Memory Layout of a Process",id:"memory-layout-of-a-process",level:3},{value:"Memory Segments Explained",id:"memory-segments-explained",level:3},{value:"1. <strong>Text/Code Segment</strong>",id:"1-textcode-segment",level:4},{value:"2. <strong>Data Segment</strong>",id:"2-data-segment",level:4},{value:"3. <strong>BSS Segment</strong> (Block Started by Symbol)",id:"3-bss-segment-block-started-by-symbol",level:4},{value:"4. <strong>Heap</strong>",id:"4-heap",level:4},{value:"5. <strong>Stack</strong>",id:"5-stack",level:4},{value:"Variable Storage in Memory",id:"variable-storage-in-memory",level:2},{value:"Example Program Analysis",id:"example-program-analysis",level:3},{value:"How CPU Executes Instructions",id:"how-cpu-executes-instructions",level:2},{value:"Assembly to Machine Code",id:"assembly-to-machine-code",level:3},{value:"CPU Registers During Execution",id:"cpu-registers-during-execution",level:3},{value:"Complete Program Execution Example",id:"complete-program-execution-example",level:2},{value:"Simple C Program",id:"simple-c-program",level:3},{value:"Step-by-Step Execution",id:"step-by-step-execution",level:3},{value:"Memory Access Pattern",id:"memory-access-pattern",level:2},{value:"Function Call Stack",id:"function-call-stack",level:2},{value:"How Function Calls Work",id:"how-function-calls-work",level:3},{value:"Function Call Example",id:"function-call-example",level:3},{value:"Dynamic Memory Allocation",id:"dynamic-memory-allocation",level:2},{value:"Heap Management",id:"heap-management",level:3},{value:"malloc/free Process",id:"mallocfree-process",level:3},{value:"CPU Pipeline",id:"cpu-pipeline",level:2},{value:"Modern CPUs Execute Multiple Instructions Simultaneously",id:"modern-cpus-execute-multiple-instructions-simultaneously",level:3},{value:"Pipeline Stages",id:"pipeline-stages",level:3},{value:"Cache Memory",id:"cache-memory",level:2},{value:"How Cache Works",id:"how-cache-works",level:3},{value:"Cache Line Example",id:"cache-line-example",level:3},{value:"Virtual Memory",id:"virtual-memory",level:2},{value:"Virtual to Physical Address Translation",id:"virtual-to-physical-address-translation",level:3},{value:"Page Table Structure",id:"page-table-structure",level:3},{value:"Complete System View",id:"complete-system-view",level:2},{value:"Performance Comparison",id:"performance-comparison",level:2},{value:"Access Time Comparison",id:"access-time-comparison",level:3},{value:"Human-Scale Time Analogy",id:"human-scale-time-analogy",level:3},{value:"Key Takeaways",id:"key-takeaways",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"how-programs-execute-cpu-ram--memory-management",children:"How Programs Execute: CPU, RAM & Memory Management"})}),"\n",(0,a.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(n.p,{children:"When you run a program, an intricate dance occurs between the CPU, RAM, and storage. This document explains exactly how your computer transforms code into actions."}),"\n",(0,a.jsx)(n.h2,{id:"computer-architecture-fundamentals",children:"Computer Architecture Fundamentals"}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    subgraph "Computer System"\n        CPU[CPU - Central Processing Unit<br/>The Brain]\n        RAM[RAM - Random Access Memory<br/>Working Space]\n        STORAGE[Storage - Hard Drive/SSD<br/>Permanent Storage]\n        IO[Input/Output Devices<br/>Keyboard, Mouse, Display]\n    end\n\n    CPU <--\x3e |Fast Access<br/>Nanoseconds| RAM\n    RAM <--\x3e |Slower<br/>Microseconds| STORAGE\n    CPU <--\x3e |Very Fast<br/>Cycles| CACHE[CPU Cache<br/>L1, L2, L3]\n    CPU <--\x3e IO\n\n    style CPU fill:#ff6b6b\n    style RAM fill:#4ecdc4\n    style STORAGE fill:#45b7d1\n    style CACHE fill:#ffd93d'}),"\n",(0,a.jsx)(n.h2,{id:"cpu-architecture",children:"CPU Architecture"}),"\n",(0,a.jsx)(n.h3,{id:"inside-the-cpu",children:"Inside the CPU"}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    subgraph "CPU Die"\n        subgraph "Core 1"\n            ALU1[ALU<br/>Arithmetic Logic Unit]\n            CU1[Control Unit<br/>Instruction Decoder]\n            REG1[Registers<br/>Fast Storage]\n            L1_1[L1 Cache<br/>~32 KB]\n        end\n\n        subgraph "Core 2"\n            ALU2[ALU]\n            CU2[Control Unit]\n            REG2[Registers]\n            L1_2[L1 Cache]\n        end\n\n        subgraph "Core 3"\n            ALU3[ALU]\n            CU3[Control Unit]\n            REG3[Registers]\n            L1_3[L1 Cache]\n        end\n\n        subgraph "Core 4"\n            ALU4[ALU]\n            CU4[Control Unit]\n            REG4[Registers]\n            L1_4[L1 Cache]\n        end\n\n        L2[L2 Cache<br/>~256 KB per core]\n        L3[L3 Cache<br/>~8-32 MB shared]\n    end\n\n    L1_1 --\x3e L2\n    L1_2 --\x3e L2\n    L1_3 --\x3e L2\n    L1_4 --\x3e L2\n    L2 --\x3e L3\n    L3 --\x3e RAM[System RAM]\n\n    style ALU1 fill:#ff6b6b\n    style CU1 fill:#4ecdc4\n    style REG1 fill:#ffd93d\n    style L1_1 fill:#a8e6cf'}),"\n",(0,a.jsx)(n.h3,{id:"key-cpu-components",children:"Key CPU Components"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Component"}),(0,a.jsx)(n.th,{children:"Purpose"}),(0,a.jsx)(n.th,{children:"Speed"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Registers"})}),(0,a.jsx)(n.td,{children:"Store immediate data for processing"}),(0,a.jsx)(n.td,{children:"1 cycle (~0.3 ns)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"L1 Cache"})}),(0,a.jsx)(n.td,{children:"First-level cache, fastest memory"}),(0,a.jsx)(n.td,{children:"3-4 cycles (~1 ns)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"L2 Cache"})}),(0,a.jsx)(n.td,{children:"Second-level cache"}),(0,a.jsx)(n.td,{children:"10-20 cycles (~3 ns)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"L3 Cache"})}),(0,a.jsx)(n.td,{children:"Third-level cache, shared"}),(0,a.jsx)(n.td,{children:"30-70 cycles (~10 ns)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"RAM"})}),(0,a.jsx)(n.td,{children:"Main system memory"}),(0,a.jsx)(n.td,{children:"100-300 cycles (~100 ns)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"SSD"})}),(0,a.jsx)(n.td,{children:"Solid state storage"}),(0,a.jsx)(n.td,{children:"~50,000 ns"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"HDD"})}),(0,a.jsx)(n.td,{children:"Hard disk drive"}),(0,a.jsx)(n.td,{children:"~5,000,000 ns"})]})]})]}),"\n",(0,a.jsx)(n.h2,{id:"program-execution-flow",children:"Program Execution Flow"}),"\n",(0,a.jsx)(n.h3,{id:"from-storage-to-execution",children:"From Storage to Execution"}),"\n",(0,a.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant User\n    participant OS as Operating System\n    participant Disk as Hard Drive/SSD\n    participant RAM as System RAM\n    participant CPU\n    participant Cache\n\n    User->>OS: Double-click program.exe\n    OS->>Disk: Locate program file\n    Disk--\x3e>OS: Program binary found\n\n    OS->>OS: Allocate memory space\n    OS->>Disk: Read program into RAM\n    Disk--\x3e>RAM: Load executable code\n    Disk--\x3e>RAM: Load required libraries\n\n    OS->>RAM: Create process structure\n    OS->>RAM: Initialize stack and heap\n\n    Note over OS,RAM: Program now in memory\n\n    OS->>CPU: Schedule process\n    CPU->>RAM: Fetch first instruction\n    RAM--\x3e>Cache: Load instruction\n    Cache--\x3e>CPU: Instruction ready\n\n    loop Execution Cycle\n        CPU->>CPU: Decode instruction\n        CPU->>CPU: Execute instruction\n        CPU->>Cache: Fetch next instruction\n        Cache->>RAM: Cache miss? Load from RAM\n    end\n\n    CPU->>RAM: Read/Write data\n    CPU->>OS: System calls for I/O\n\n    User->>OS: Close program\n    OS->>RAM: Free allocated memory\n    OS->>CPU: Remove from schedule"}),"\n",(0,a.jsx)(n.h2,{id:"memory-hierarchy",children:"Memory Hierarchy"}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TD\n    A[CPU Registers<br/>~1 KB<br/>0.3 ns access] --\x3e B[L1 Cache<br/>32-64 KB<br/>1 ns access]\n    B --\x3e C[L2 Cache<br/>256-512 KB<br/>3 ns access]\n    C --\x3e D[L3 Cache<br/>8-32 MB<br/>10 ns access]\n    D --\x3e E[Main RAM<br/>8-64 GB<br/>100 ns access]\n    E --\x3e F[SSD Storage<br/>256 GB - 4 TB<br/>50 \u03bcs access]\n    F --\x3e G[HDD Storage<br/>500 GB - 10 TB<br/>5 ms access]\n\n    style A fill:#ff0000\n    style B fill:#ff6b00\n    style C fill:#ffa500\n    style D fill:#ffd700\n    style E fill:#90ee90\n    style F fill:#4ecdc4\n    style G fill:#45b7d1\n\n    Note1[Faster & Smaller<br/>More Expensive]\n    Note2[Slower & Larger<br/>Less Expensive]"}),"\n",(0,a.jsx)(n.h2,{id:"cpu-instruction-cycle-fetch-decode-execute",children:"CPU Instruction Cycle (Fetch-Decode-Execute)"}),"\n",(0,a.jsx)(n.mermaid,{value:'flowchart LR\n    A[Fetch] --\x3e B[Decode]\n    B --\x3e C[Execute]\n    C --\x3e D[Store]\n    D --\x3e A\n\n    subgraph "1. Fetch"\n        A1[PC points to<br/>next instruction]\n        A2[Load instruction<br/>from memory]\n        A3[Increment PC]\n    end\n\n    subgraph "2. Decode"\n        B1[Instruction<br/>Register]\n        B2[Control Unit<br/>interprets]\n        B3[Identify<br/>operands]\n    end\n\n    subgraph "3. Execute"\n        C1[ALU performs<br/>operation]\n        C2[Access memory<br/>if needed]\n        C3[Compute result]\n    end\n\n    subgraph "4. Store"\n        D1[Write result<br/>to register]\n        D2[Update flags]\n        D3[Write to memory<br/>if needed]\n    end\n\n    style A fill:#ff6b6b\n    style B fill:#4ecdc4\n    style C fill:#ffd93d\n    style D fill:#95e1d3'}),"\n",(0,a.jsx)(n.h3,{id:"example-adding-two-numbers",children:"Example: Adding Two Numbers"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"Instruction: ADD R1, R2, R3  (R1 = R2 + R3)\n\n1. FETCH:\n   - PC = 0x1000 (program counter points to instruction)\n   - Load instruction from memory address 0x1000\n   - PC = 0x1004 (move to next instruction)\n\n2. DECODE:\n   - Opcode: ADD\n   - Operand 1: R2 (register 2)\n   - Operand 2: R3 (register 3)\n   - Destination: R1 (register 1)\n\n3. EXECUTE:\n   - Read value from R2 (e.g., 10)\n   - Read value from R3 (e.g., 20)\n   - ALU performs: 10 + 20 = 30\n\n4. STORE:\n   - Write result (30) to R1\n   - Update flags (zero flag, carry flag, etc.)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"ram-organization-for-a-program",children:"RAM Organization for a Program"}),"\n",(0,a.jsx)(n.h3,{id:"memory-layout-of-a-process",children:"Memory Layout of a Process"}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    subgraph "Virtual Memory Space - 4GB Example"\n        KERNEL[Kernel Space<br/>0xC0000000 - 0xFFFFFFFF<br/>OS reserved]\n\n        STACK[Stack<br/>Grows downward<br/>\u2193<br/>Local variables<br/>Function calls<br/>Return addresses]\n\n        UNUSED[Unused Memory<br/>\u2195<br/>Available space]\n\n        HEAP[Heap<br/>Grows upward<br/>\u2191<br/>Dynamic memory<br/>malloc/new allocations]\n\n        BSS[BSS Segment<br/>Uninitialized global variables<br/>Zero-initialized]\n\n        DATA[Data Segment<br/>Initialized global variables<br/>Static variables]\n\n        TEXT[Text/Code Segment<br/>Program instructions<br/>Read-only executable code<br/>0x08048000]\n    end\n\n    KERNEL --\x3e STACK\n    STACK --\x3e UNUSED\n    UNUSED --\x3e HEAP\n    HEAP --\x3e BSS\n    BSS --\x3e DATA\n    DATA --\x3e TEXT\n\n    style KERNEL fill:#ff6b6b\n    style STACK fill:#ffd93d\n    style HEAP fill:#a8e6cf\n    style BSS fill:#dfe6e9\n    style DATA fill:#74b9ff\n    style TEXT fill:#fd79a8'}),"\n",(0,a.jsx)(n.h3,{id:"memory-segments-explained",children:"Memory Segments Explained"}),"\n",(0,a.jsxs)(n.h4,{id:"1-textcode-segment",children:["1. ",(0,a.jsx)(n.strong,{children:"Text/Code Segment"})]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Contains compiled machine code (instructions)"}),"\n",(0,a.jsx)(n.li,{children:"Read-only and executable"}),"\n",(0,a.jsx)(n.li,{children:"Shared among multiple instances of same program"}),"\n",(0,a.jsx)(n.li,{children:"Fixed size at load time"}),"\n"]}),"\n",(0,a.jsxs)(n.h4,{id:"2-data-segment",children:["2. ",(0,a.jsx)(n.strong,{children:"Data Segment"})]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Initialized Data"}),": Global and static variables with initial values","\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-c",children:"int globalVar = 100;  // Stored in data segment\nstatic int count = 0; // Stored in data segment\n"})}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.h4,{id:"3-bss-segment-block-started-by-symbol",children:["3. ",(0,a.jsx)(n.strong,{children:"BSS Segment"})," (Block Started by Symbol)"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Uninitialized global and static variables"}),"\n",(0,a.jsx)(n.li,{children:"Automatically initialized to zero"}),"\n",(0,a.jsxs)(n.li,{children:["Doesn't occupy space in executable file","\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-c",children:"int globalArray[1000]; // Stored in BSS\nstatic int flag;       // Stored in BSS\n"})}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.h4,{id:"4-heap",children:["4. ",(0,a.jsx)(n.strong,{children:"Heap"})]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Dynamic memory allocation"}),"\n",(0,a.jsx)(n.li,{children:"Grows upward toward higher addresses"}),"\n",(0,a.jsx)(n.li,{children:"Managed by programmer (malloc/free, new/delete)"}),"\n",(0,a.jsxs)(n.li,{children:["Exists until program ends or explicitly freed","\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-c",children:"int* ptr = malloc(sizeof(int) * 100); // Allocated on heap\n"})}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.h4,{id:"5-stack",children:["5. ",(0,a.jsx)(n.strong,{children:"Stack"})]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Automatic memory allocation"}),"\n",(0,a.jsx)(n.li,{children:"Grows downward toward lower addresses"}),"\n",(0,a.jsx)(n.li,{children:"Stores local variables, function parameters, return addresses"}),"\n",(0,a.jsxs)(n.li,{children:["Automatically cleaned up when function returns","\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-c",children:"void function() {\n    int localVar = 10; // Stored on stack\n}\n"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"variable-storage-in-memory",children:"Variable Storage in Memory"}),"\n",(0,a.jsx)(n.h3,{id:"example-program-analysis",children:"Example Program Analysis"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-c",children:'#include <stdio.h>\n#include <stdlib.h>\n\nint globalVar = 100;           // Data segment\nstatic int staticVar = 200;    // Data segment\nint uninitGlobal;              // BSS segment\n\nvoid function(int param) {      // param on stack\n    int localVar = 10;          // Stack\n    static int staticLocal = 5; // Data segment\n    int* heapVar = malloc(sizeof(int)); // Pointer on stack, data on heap\n    *heapVar = 20;              // Value stored on heap\n\n    printf("Address of param: %p\\n", &param);\n    printf("Address of localVar: %p\\n", &localVar);\n    printf("Address of heapVar: %p\\n", heapVar);\n\n    free(heapVar);\n}\n\nint main() {\n    int mainLocal = 5;          // Stack\n    function(mainLocal);\n    return 0;\n}\n'})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    subgraph "Memory Map"\n        subgraph "Stack (High Address)"\n            S1[return address]\n            S2[param = 5]\n            S3[localVar = 10]\n            S4[heapVar pointer<br/>points to heap]\n            S5[mainLocal = 5]\n            S6[main return address]\n        end\n\n        subgraph "Heap"\n            H1[malloc block<br/>value = 20]\n            H2[Other allocations]\n        end\n\n        subgraph "BSS"\n            B1[uninitGlobal = 0]\n        end\n\n        subgraph "Data"\n            D1[globalVar = 100]\n            D2[staticVar = 200]\n            D3[staticLocal = 5]\n        end\n\n        subgraph "Text"\n            T1[main function code]\n            T2[function code]\n            T3[printf code]\n        end\n    end\n\n    S4 -.pointer.-> H1\n\n    style S1 fill:#ffd93d\n    style S2 fill:#ffd93d\n    style S3 fill:#ffd93d\n    style S4 fill:#ffd93d\n    style S5 fill:#ffd93d\n    style H1 fill:#a8e6cf\n    style D1 fill:#74b9ff\n    style T1 fill:#fd79a8'}),"\n",(0,a.jsx)(n.h2,{id:"how-cpu-executes-instructions",children:"How CPU Executes Instructions"}),"\n",(0,a.jsx)(n.h3,{id:"assembly-to-machine-code",children:"Assembly to Machine Code"}),"\n",(0,a.jsx)(n.mermaid,{value:"flowchart TD\n    A[High-Level Code<br/>int c = a + b] --\x3e B[Compiler]\n    B --\x3e C[Assembly Code<br/>MOV R1, a<br/>MOV R2, b<br/>ADD R3, R1, R2<br/>MOV c, R3]\n    C --\x3e D[Assembler]\n    D --\x3e E[Machine Code<br/>10110001 00000001<br/>10110010 00000010<br/>00000011 00011010<br/>10001001 00000011]\n    E --\x3e F[CPU Execution]\n\n    style A fill:#a8e6cf\n    style C fill:#ffd93d\n    style E fill:#ff6b6b"}),"\n",(0,a.jsx)(n.h3,{id:"cpu-registers-during-execution",children:"CPU Registers During Execution"}),"\n",(0,a.jsx)(n.mermaid,{value:'graph LR\n    subgraph "CPU Registers"\n        PC[Program Counter<br/>PC: 0x1000]\n        IR[Instruction Register<br/>IR: ADD R1, R2]\n        ACC[Accumulator<br/>ACC: 30]\n        R1[Register R1<br/>R1: 10]\n        R2[Register R2<br/>R2: 20]\n        SP[Stack Pointer<br/>SP: 0xBFFF]\n        BP[Base Pointer<br/>BP: 0xBFF0]\n        FLAGS[Flags Register<br/>Z:0 C:0 O:0]\n    end\n\n    MAR[Memory Address Register<br/>MAR: 0x1000]\n    MDR[Memory Data Register<br/>MDR: 10110001]\n\n    PC --\x3e MAR\n    MAR --\x3e MEM[RAM]\n    MEM --\x3e MDR\n    MDR --\x3e IR\n\n    style PC fill:#ff6b6b\n    style IR fill:#4ecdc4\n    style ACC fill:#ffd93d\n    style R1 fill:#a8e6cf\n    style R2 fill:#a8e6cf'}),"\n",(0,a.jsx)(n.h2,{id:"complete-program-execution-example",children:"Complete Program Execution Example"}),"\n",(0,a.jsx)(n.h3,{id:"simple-c-program",children:"Simple C Program"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-c",children:"int main() {\n    int a = 5;\n    int b = 10;\n    int c = a + b;\n    return c;\n}\n"})}),"\n",(0,a.jsx)(n.h3,{id:"step-by-step-execution",children:"Step-by-Step Execution"}),"\n",(0,a.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant OS\n    participant RAM\n    participant CPU\n    participant ALU\n    participant Registers\n\n    Note over OS,Registers: Program Loading Phase\n    OS->>RAM: Load program binary\n    OS->>RAM: Allocate stack space\n    OS->>RAM: Setup process structure\n\n    Note over OS,Registers: Execution Phase\n    OS->>CPU: Schedule process\n    CPU->>RAM: Fetch instruction at PC\n    RAM--\x3e>CPU: MOV [SP-4], 5\n\n    Note over CPU: int a = 5\n    CPU->>Registers: Decode instruction\n    CPU->>ALU: Calculate address: SP-4\n    ALU--\x3e>CPU: Address = 0xBFFC\n    CPU->>RAM: Write 5 to 0xBFFC\n\n    Note over CPU: int b = 10\n    CPU->>RAM: Fetch next instruction\n    RAM--\x3e>CPU: MOV [SP-8], 10\n    CPU->>ALU: Calculate address: SP-8\n    ALU--\x3e>CPU: Address = 0xBFF8\n    CPU->>RAM: Write 10 to 0xBFF8\n\n    Note over CPU: int c = a + b\n    CPU->>RAM: Fetch next instruction\n    RAM--\x3e>CPU: ADD instruction\n    CPU->>RAM: Read value from 0xBFFC\n    RAM--\x3e>CPU: a = 5\n    CPU->>RAM: Read value from 0xBFF8\n    RAM--\x3e>CPU: b = 10\n    CPU->>ALU: Perform 5 + 10\n    ALU--\x3e>CPU: Result = 15\n    CPU->>RAM: Write 15 to 0xBFF4\n\n    Note over CPU: return c\n    CPU->>RAM: Read 0xBFF4\n    RAM--\x3e>CPU: c = 15\n    CPU->>Registers: Set return value = 15\n    CPU->>OS: Program exit, return 15\n    OS->>RAM: Free allocated memory"}),"\n",(0,a.jsx)(n.h2,{id:"memory-access-pattern",children:"Memory Access Pattern"}),"\n",(0,a.jsx)(n.mermaid,{value:"flowchart TD\n    A[CPU needs data] --\x3e B{In Registers?}\n    B --\x3e|Yes| C[Use directly<br/>~0.3 ns]\n    B --\x3e|No| D{In L1 Cache?}\n    D --\x3e|Yes| E[Load from L1<br/>~1 ns]\n    D --\x3e|No| F{In L2 Cache?}\n    F --\x3e|Yes| G[Load from L2<br/>~3 ns]\n    F --\x3e|No| H{In L3 Cache?}\n    H --\x3e|Yes| I[Load from L3<br/>~10 ns]\n    H --\x3e|No| J[Load from RAM<br/>~100 ns]\n\n    J --\x3e K[Store in Cache]\n    I --\x3e K\n    G --\x3e K\n    E --\x3e K\n    K --\x3e L[CPU processes data]\n    C --\x3e L\n\n    style C fill:#00ff00\n    style E fill:#90ee90\n    style G fill:#ffff00\n    style I fill:#ffa500\n    style J fill:#ff0000"}),"\n",(0,a.jsx)(n.h2,{id:"function-call-stack",children:"Function Call Stack"}),"\n",(0,a.jsx)(n.h3,{id:"how-function-calls-work",children:"How Function Calls Work"}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    subgraph "Stack Growth During Function Calls"\n        direction TB\n\n        S10[Stack Top<br/>0xBFFC]\n        S9[Local var c = 15]\n        S8[Local var b = 10]\n        S7[Local var a = 5]\n        S6[Return address<br/>to main]\n        S5[Saved base pointer]\n\n        S4[function2 param = 7]\n        S3[Return address<br/>to function1]\n        S2[Saved base pointer]\n\n        S1[function1 param = 5]\n        S0[Return address<br/>to main]\n\n        M1[main local vars]\n        M0[Stack Base<br/>0xC000]\n    end\n\n    S10 -.current SP.-> SP[Stack Pointer]\n    S5 -.current BP.-> BP[Base Pointer]\n\n    style S10 fill:#ff6b6b\n    style S6 fill:#4ecdc4\n    style S3 fill:#4ecdc4\n    style S0 fill:#4ecdc4'}),"\n",(0,a.jsx)(n.h3,{id:"function-call-example",children:"Function Call Example"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-c",children:"void function2(int x) {\n    int local2 = x * 2;\n    return;\n}\n\nvoid function1(int y) {\n    int local1 = y + 1;\n    function2(local1);\n    return;\n}\n\nint main() {\n    int a = 5;\n    function1(a);\n    return 0;\n}\n"})}),"\n",(0,a.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant Main\n    participant Stack\n    participant CPU\n\n    Note over Main,CPU: main() executes\n    Main->>Stack: Push local var a = 5\n    Main->>Stack: Push parameter 5\n    Main->>Stack: Push return address\n    Main->>CPU: Call function1\n\n    Note over Main,CPU: function1() executes\n    CPU->>Stack: Push base pointer\n    CPU->>Stack: Push local1 = 6\n    CPU->>Stack: Push parameter 6\n    CPU->>Stack: Push return address\n    CPU->>CPU: Call function2\n\n    Note over Main,CPU: function2() executes\n    CPU->>Stack: Push base pointer\n    CPU->>Stack: Push local2 = 12\n    CPU->>CPU: Execute function body\n    CPU->>Stack: Pop local2\n    CPU->>Stack: Pop base pointer\n    CPU->>Stack: Pop return address\n    CPU->>CPU: Return to function1\n\n    Note over Main,CPU: Back in function1()\n    CPU->>Stack: Pop parameter\n    CPU->>Stack: Pop local1\n    CPU->>Stack: Pop base pointer\n    CPU->>Stack: Pop return address\n    CPU->>Main: Return to main\n\n    Note over Main,CPU: Back in main()\n    Main->>Stack: Pop parameter\n    Main->>Stack: Pop local var a"}),"\n",(0,a.jsx)(n.h2,{id:"dynamic-memory-allocation",children:"Dynamic Memory Allocation"}),"\n",(0,a.jsx)(n.h3,{id:"heap-management",children:"Heap Management"}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    subgraph "Heap Memory"\n        direction LR\n        FREE1[Free Block<br/>100 bytes]\n        ALLOC1[Allocated<br/>50 bytes<br/>ptr1]\n        FREE2[Free Block<br/>200 bytes]\n        ALLOC2[Allocated<br/>80 bytes<br/>ptr2]\n        FREE3[Free Block<br/>150 bytes]\n        ALLOC3[Allocated<br/>120 bytes<br/>ptr3]\n        FREE4[Free Block<br/>300 bytes]\n    end\n\n    HEAP_START[Heap Start<br/>Low Address] --\x3e FREE1\n    FREE4 --\x3e HEAP_END[Heap End<br/>High Address]\n\n    style FREE1 fill:#90ee90\n    style ALLOC1 fill:#ff6b6b\n    style FREE2 fill:#90ee90\n    style ALLOC2 fill:#ff6b6b\n    style FREE3 fill:#90ee90\n    style ALLOC3 fill:#ff6b6b\n    style FREE4 fill:#90ee90'}),"\n",(0,a.jsx)(n.h3,{id:"mallocfree-process",children:"malloc/free Process"}),"\n",(0,a.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant Code\n    participant Malloc\n    participant Heap\n    participant OS\n\n    Note over Code,OS: Memory Allocation\n    Code->>Malloc: malloc(100)\n    Malloc->>Heap: Search free list\n    Heap--\x3e>Malloc: Found block at 0x5000\n    Malloc->>Heap: Mark 100 bytes as allocated\n    Malloc->>Heap: Update metadata\n    Malloc--\x3e>Code: Return pointer 0x5000\n\n    Note over Code,OS: Using Memory\n    Code->>Heap: Write data to 0x5000\n\n    Note over Code,OS: Memory Deallocation\n    Code->>Malloc: free(0x5000)\n    Malloc->>Heap: Mark block as free\n    Malloc->>Heap: Coalesce with adjacent free blocks\n    Malloc->>Heap: Add to free list\n    Malloc--\x3e>Code: Memory freed"}),"\n",(0,a.jsx)(n.h2,{id:"cpu-pipeline",children:"CPU Pipeline"}),"\n",(0,a.jsx)(n.h3,{id:"modern-cpus-execute-multiple-instructions-simultaneously",children:"Modern CPUs Execute Multiple Instructions Simultaneously"}),"\n",(0,a.jsx)(n.mermaid,{value:"gantt\n    title CPU Pipeline Execution (5-stage)\n    dateFormat X\n    axisFormat %L\n\n    section Instruction 1\n    Fetch       :0, 1\n    Decode      :1, 1\n    Execute     :2, 1\n    Memory      :3, 1\n    Writeback   :4, 1\n\n    section Instruction 2\n    Fetch       :1, 1\n    Decode      :2, 1\n    Execute     :3, 1\n    Memory      :4, 1\n    Writeback   :5, 1\n\n    section Instruction 3\n    Fetch       :2, 1\n    Decode      :3, 1\n    Execute     :4, 1\n    Memory      :5, 1\n    Writeback   :6, 1\n\n    section Instruction 4\n    Fetch       :3, 1\n    Decode      :4, 1\n    Execute     :5, 1\n    Memory      :6, 1\n    Writeback   :7, 1\n\n    section Instruction 5\n    Fetch       :4, 1\n    Decode      :5, 1\n    Execute     :6, 1\n    Memory      :7, 1\n    Writeback   :8, 1"}),"\n",(0,a.jsx)(n.h3,{id:"pipeline-stages",children:"Pipeline Stages"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Fetch (IF)"}),": Get instruction from memory"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Decode (ID)"}),": Interpret instruction and read registers"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Execute (EX)"}),": Perform operation in ALU"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Memory (MEM)"}),": Access memory if needed"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Writeback (WB)"}),": Write result to register"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"cache-memory",children:"Cache Memory"}),"\n",(0,a.jsx)(n.h3,{id:"how-cache-works",children:"How Cache Works"}),"\n",(0,a.jsx)(n.mermaid,{value:"flowchart TD\n    A[CPU needs data at address 0x1000] --\x3e B{Check L1 Cache}\n    B --\x3e|Hit| C[Return data immediately<br/>~1 ns]\n    B --\x3e|Miss| D{Check L2 Cache}\n    D --\x3e|Hit| E[Load to L1<br/>Return data<br/>~3 ns]\n    D --\x3e|Miss| F{Check L3 Cache}\n    F --\x3e|Hit| G[Load to L2 and L1<br/>Return data<br/>~10 ns]\n    F --\x3e|Miss| H[Load from RAM<br/>Load to all caches<br/>~100 ns]\n\n    style C fill:#00ff00\n    style E fill:#90ee90\n    style G fill:#ffff00\n    style H fill:#ff6b6b"}),"\n",(0,a.jsx)(n.h3,{id:"cache-line-example",children:"Cache Line Example"}),"\n",(0,a.jsx)(n.mermaid,{value:'graph LR\n    subgraph "Memory Address 0x1000"\n        M1[Byte 0]\n        M2[Byte 1]\n        M3[Byte 2]\n        M4[...]\n        M5[Byte 63]\n    end\n\n    subgraph "Cache Line (64 bytes)"\n        C1[Tag<br/>0x1000]\n        C2[Valid Bit]\n        C3[Data Block<br/>64 bytes]\n    end\n\n    M1 --\x3e C3\n    M2 --\x3e C3\n    M3 --\x3e C3\n    M5 --\x3e C3\n\n    style C1 fill:#4ecdc4\n    style C2 fill:#ffd93d\n    style C3 fill:#a8e6cf'}),"\n",(0,a.jsx)(n.h2,{id:"virtual-memory",children:"Virtual Memory"}),"\n",(0,a.jsx)(n.h3,{id:"virtual-to-physical-address-translation",children:"Virtual to Physical Address Translation"}),"\n",(0,a.jsx)(n.mermaid,{value:"flowchart TD\n    A[Program uses<br/>Virtual Address<br/>0x08048000] --\x3e B[CPU's MMU<br/>Memory Management Unit]\n    B --\x3e C{Check TLB<br/>Translation Lookaside Buffer}\n    C --\x3e|Hit| D[Get Physical Address<br/>0x00402000]\n    C --\x3e|Miss| E[Page Table Lookup]\n    E --\x3e F{Page in RAM?}\n    F --\x3e|Yes| G[Update TLB<br/>Get Physical Address]\n    F --\x3e|No| H[Page Fault]\n    H --\x3e I[Load page from Disk]\n    I --\x3e J[Update Page Table]\n    J --\x3e G\n\n    D --\x3e K[Access Physical RAM<br/>at 0x00402000]\n    G --\x3e K\n\n    style A fill:#a8e6cf\n    style D fill:#90ee90\n    style K fill:#4ecdc4\n    style H fill:#ff6b6b"}),"\n",(0,a.jsx)(n.h3,{id:"page-table-structure",children:"Page Table Structure"}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    subgraph "Virtual Memory Space (4GB)"\n        V1[Page 0<br/>0x00000000]\n        V2[Page 1<br/>0x00001000]\n        V3[Page 2<br/>0x00002000]\n        V4[Page 3<br/>0x00003000]\n        V5[...]\n    end\n\n    subgraph "Page Table"\n        PT1[Entry 0: Frame 5]\n        PT2[Entry 1: Frame 2]\n        PT3[Entry 2: On Disk]\n        PT4[Entry 3: Frame 8]\n        PT5[...]\n    end\n\n    subgraph "Physical RAM (2GB)"\n        P1[Frame 0]\n        P2[Frame 1]\n        P3[Frame 2<br/>Page 1 data]\n        P4[Frame 3]\n        P5[Frame 4]\n        P6[Frame 5<br/>Page 0 data]\n        P7[...]\n        P8[Frame 8<br/>Page 3 data]\n    end\n\n    V1 --\x3e PT1\n    V2 --\x3e PT2\n    V3 --\x3e PT3\n    V4 --\x3e PT4\n\n    PT1 --\x3e P6\n    PT2 --\x3e P3\n    PT3 -.Page Fault.-> DISK[Swap on Disk]\n    PT4 --\x3e P8\n\n    style PT3 fill:#ff6b6b\n    style DISK fill:#45b7d1'}),"\n",(0,a.jsx)(n.h2,{id:"complete-system-view",children:"Complete System View"}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    subgraph "Application Layer"\n        APP[Your Program<br/>program.exe]\n    end\n\n    subgraph "Operating System Layer"\n        OS[OS Kernel]\n        SCHEDULER[Process Scheduler]\n        MM[Memory Manager]\n        FS[File System]\n    end\n\n    subgraph "Hardware Layer"\n        subgraph "CPU"\n            CORE1[Core 1]\n            CORE2[Core 2]\n            CACHE[L3 Cache]\n        end\n\n        RAM[RAM<br/>8-64 GB]\n        STORAGE[Storage<br/>SSD/HDD]\n        GPU[GPU]\n        IO[I/O Devices]\n    end\n\n    APP --\x3e OS\n    OS --\x3e SCHEDULER\n    OS --\x3e MM\n    OS --\x3e FS\n\n    SCHEDULER --\x3e CORE1\n    SCHEDULER --\x3e CORE2\n    MM --\x3e RAM\n    FS --\x3e STORAGE\n\n    CORE1 <--\x3e CACHE\n    CORE2 <--\x3e CACHE\n    CACHE <--\x3e RAM\n\n    OS --\x3e GPU\n    OS --\x3e IO\n\n    style APP fill:#a8e6cf\n    style OS fill:#4ecdc4\n    style CPU fill:#ff6b6b\n    style RAM fill:#ffd93d\n    style STORAGE fill:#45b7d1'}),"\n",(0,a.jsx)(n.h2,{id:"performance-comparison",children:"Performance Comparison"}),"\n",(0,a.jsx)(n.h3,{id:"access-time-comparison",children:"Access Time Comparison"}),"\n",(0,a.jsx)(n.mermaid,{value:"graph LR\n    A[CPU Register<br/>0.3 ns<br/>1x]\n    B[L1 Cache<br/>1 ns<br/>3x]\n    C[L2 Cache<br/>3 ns<br/>10x]\n    D[L3 Cache<br/>10 ns<br/>33x]\n    E[RAM<br/>100 ns<br/>333x]\n    F[SSD<br/>50 \u03bcs<br/>166,666x]\n    G[HDD<br/>5 ms<br/>16,666,666x]\n\n    A --\x3e B\n    B --\x3e C\n    C --\x3e D\n    D --\x3e E\n    E --\x3e F\n    F --\x3e G\n\n    style A fill:#00ff00\n    style B fill:#90ee90\n    style C fill:#ffff00\n    style D fill:#ffa500\n    style E fill:#ff6b6b\n    style F fill:#ff4757\n    style G fill:#8b0000"}),"\n",(0,a.jsx)(n.h3,{id:"human-scale-time-analogy",children:"Human-Scale Time Analogy"}),"\n",(0,a.jsx)(n.p,{children:"If accessing a CPU register took 1 second, here's how long other operations would take:"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Memory Level"}),(0,a.jsx)(n.th,{children:"Actual Time"}),(0,a.jsx)(n.th,{children:"If Register = 1 Second"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"CPU Register"}),(0,a.jsx)(n.td,{children:"0.3 ns"}),(0,a.jsx)(n.td,{children:"1 second"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"L1 Cache"}),(0,a.jsx)(n.td,{children:"1 ns"}),(0,a.jsx)(n.td,{children:"3 seconds"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"L2 Cache"}),(0,a.jsx)(n.td,{children:"3 ns"}),(0,a.jsx)(n.td,{children:"10 seconds"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"L3 Cache"}),(0,a.jsx)(n.td,{children:"10 ns"}),(0,a.jsx)(n.td,{children:"33 seconds"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"RAM"}),(0,a.jsx)(n.td,{children:"100 ns"}),(0,a.jsx)(n.td,{children:"5.5 minutes"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"SSD"}),(0,a.jsx)(n.td,{children:"50 \u03bcs"}),(0,a.jsx)(n.td,{children:"1.9 days"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"HDD"}),(0,a.jsx)(n.td,{children:"5 ms"}),(0,a.jsx)(n.td,{children:"6.4 months"})]})]})]}),"\n",(0,a.jsx)(n.h3,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Speed vs Size Trade-off"}),": Faster memory is exponentially more expensive and smaller"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Locality Matters"}),": Programs that access nearby memory locations run faster due to caching"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Cache is Critical"}),": Modern CPUs spend significant silicon area on cache to bridge the speed gap"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"RAM is Slow"}),': Despite being "fast" by human standards, RAM is ~100x slower than L1 cache']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Disk is Extremely Slow"}),": SSDs are 500,000x slower than registers; HDDs are 16 million times slower"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);