"use strict";(self.webpackChunkdev_enigma=self.webpackChunkdev_enigma||[]).push([[86010],{28453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>c});var s=r(96540);const t={},i=s.createContext(t);function l(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(i.Provider,{value:n},e.children)}},74567:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>c,toc:()=>o});var s=r(74848),t=r(28453);const i={},l="Retry, Backoff, Jitter & Resilience Patterns",c={id:"Backend System Design/Retry, Backoff, Jitter & Resilience Patterns",title:"Retry, Backoff, Jitter & Resilience Patterns",description:"\ud83d\udcda Core Concepts",source:"@site/docs/Backend System Design/Retry, Backoff, Jitter & Resilience Patterns.mdx",sourceDirName:"Backend System Design",slug:"/Backend System Design/Retry, Backoff, Jitter & Resilience Patterns",permalink:"/docs/Backend System Design/Retry, Backoff, Jitter & Resilience Patterns",draft:!1,unlisted:!1,editUrl:"https://github.com/carefree-ladka/docs/Backend System Design/Retry, Backoff, Jitter & Resilience Patterns.mdx",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Rate Limiter System Design",permalink:"/docs/Backend System Design/Rate Limiter System Design"},next:{title:"Stream Processing & Message Queue Systems: System Design Guide",permalink:"/docs/Backend System Design/Stream Processing & Message Queue Systems: System Design Guide"}},a={},o=[{value:"\ud83d\udcda Core Concepts",id:"-core-concepts",level:2},{value:"1\ufe0f\u20e3 Retry",id:"1\ufe0f\u20e3-retry",level:3},{value:"2\ufe0f\u20e3 Backoff",id:"2\ufe0f\u20e3-backoff",level:3},{value:"3\ufe0f\u20e3 Jitter",id:"3\ufe0f\u20e3-jitter",level:3},{value:"4\ufe0f\u20e3 Circuit Breaker",id:"4\ufe0f\u20e3-circuit-breaker",level:3},{value:"5\ufe0f\u20e3 Rate Limiting &amp; Throttling",id:"5\ufe0f\u20e3-rate-limiting--throttling",level:3},{value:"6\ufe0f\u20e3 Dead Letter Queue (DLQ)",id:"6\ufe0f\u20e3-dead-letter-queue-dlq",level:3},{value:"\ud83c\udfaf Real-World Example: Payment Processing System",id:"-real-world-example-payment-processing-system",level:2},{value:"Scenario",id:"scenario",level:3},{value:"Architecture",id:"architecture",level:3},{value:"Step-by-Step Flow",id:"step-by-step-flow",level:3},{value:"<strong>Step 1: Initial Request</strong>",id:"step-1-initial-request",level:4},{value:"<strong>Step 2: Circuit Breaker Check</strong>",id:"step-2-circuit-breaker-check",level:4},{value:"<strong>Step 3: First Attempt</strong>",id:"step-3-first-attempt",level:4},{value:"<strong>Step 4: Retry Logic Kicks In</strong>",id:"step-4-retry-logic-kicks-in",level:4},{value:"<strong>Step 5: Success Response</strong>",id:"step-5-success-response",level:4},{value:"What If All Retries Failed?",id:"what-if-all-retries-failed",level:3},{value:"<strong>Outcome:</strong>",id:"outcome",level:4},{value:"\ud83d\udcca Configuration Examples",id:"-configuration-examples",level:2},{value:"Retry Policy",id:"retry-policy",level:3},{value:"Circuit Breaker Config",id:"circuit-breaker-config",level:3},{value:"\ud83c\udfa4 Interview Talking Points",id:"-interview-talking-points",level:2},{value:"1. <strong>Why Retries Alone Are Dangerous</strong>",id:"1-why-retries-alone-are-dangerous",level:3},{value:"2. <strong>Retry + Backoff + Jitter = Best Practice</strong>",id:"2-retry--backoff--jitter--best-practice",level:3},{value:"3. <strong>Circuit Breakers for Cascading Failure Prevention</strong>",id:"3-circuit-breakers-for-cascading-failure-prevention",level:3},{value:"4. <strong>Idempotency is Critical</strong>",id:"4-idempotency-is-critical",level:3},{value:"5. <strong>Observability Matters</strong>",id:"5-observability-matters",level:3},{value:"6. <strong>Dead Letter Queues for Async Systems</strong>",id:"6-dead-letter-queues-for-async-systems",level:3},{value:"\u26a1 Quick Formula for Interviews",id:"-quick-formula-for-interviews",level:2},{value:"\ud83d\udd0d Common Interview Questions",id:"-common-interview-questions",level:2},{value:"\ud83d\udee0\ufe0f Implementation Considerations",id:"\ufe0f-implementation-considerations",level:2},{value:"Choose Your Strategy Based On:",id:"choose-your-strategy-based-on",level:3},{value:"\ud83d\udcc8 Monitoring &amp; Alerts",id:"-monitoring--alerts",level:2},{value:"\ud83c\udfaf Summary",id:"-summary",level:2}];function d(e){const n={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",mermaid:"mermaid",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"retry-backoff-jitter--resilience-patterns",children:"Retry, Backoff, Jitter & Resilience Patterns"})}),"\n",(0,s.jsx)(n.h2,{id:"-core-concepts",children:"\ud83d\udcda Core Concepts"}),"\n",(0,s.jsx)(n.h3,{id:"1\ufe0f\u20e3-retry",children:"1\ufe0f\u20e3 Retry"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"What is it?"}),"\nWhen a request fails due to transient issues (network hiccup, temporary server overload, timeout), the client automatically resends the request."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Why use it?"}),"\nMany failures in distributed systems are temporary. A simple retry often succeeds where the first attempt failed."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"\u26a0\ufe0f Pitfalls:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Retry Storms"}),": If every client blindly retries, you amplify load on an already struggling system"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Duplicate Operations"}),": Retrying non-idempotent operations (like payment processing) can cause unintended side effects"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Resource Exhaustion"}),": Aggressive retries can exhaust connection pools, thread pools, or API quotas"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"\u2705 Best Practices:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Limit retry attempts (typically 3-5 max)"}),"\n",(0,s.jsx)(n.li,{children:"Only retry safe errors (timeouts, 503, 502, connection resets)"}),"\n",(0,s.jsx)(n.li,{children:"Never retry on client errors (4xx) except 408, 429"}),"\n",(0,s.jsxs)(n.li,{children:["Use ",(0,s.jsx)(n.strong,{children:"idempotency keys"})," for state-changing operations"]}),"\n",(0,s.jsx)(n.li,{children:"Implement retry budgets to prevent cascading failures"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"2\ufe0f\u20e3-backoff",children:"2\ufe0f\u20e3 Backoff"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"What is it?"}),"\nInstead of retrying immediately, introduce an increasing delay between retry attempts."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Types:"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Fixed Backoff"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Delay: 2s \u2192 2s \u2192 2s\n"})}),"\n",(0,s.jsx)(n.p,{children:"Simple but doesn't adapt to system load."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Linear Backoff"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Delay: 1s \u2192 2s \u2192 3s \u2192 4s\n"})}),"\n",(0,s.jsx)(n.p,{children:"Gradual increase, predictable scaling."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Exponential Backoff"})," \u2b50 Most Common"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Delay: 1s \u2192 2s \u2192 4s \u2192 8s \u2192 16s\n"})}),"\n",(0,s.jsx)(n.p,{children:"Rapidly backs off, giving systems time to recover."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Why use it?"}),"\nPrevents overwhelming a struggling system and gives it breathing room to recover. Immediate retries can make problems worse."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Formula:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"delay = base_delay * (2 ^ attempt_number)\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Use Cases:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"API rate limiting (429 responses)"}),"\n",(0,s.jsx)(n.li,{children:"Database connection failures"}),"\n",(0,s.jsx)(n.li,{children:"Message queue processing"}),"\n",(0,s.jsx)(n.li,{children:"External service timeouts"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"3\ufe0f\u20e3-jitter",children:"3\ufe0f\u20e3 Jitter"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"What is it?"}),"\nAdding randomness to backoff delays to prevent synchronized retry patterns."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Why use it?"}),"\nWithout jitter, thousands of clients retry at exactly the same time (4s, 8s, 16s), creating a ",(0,s.jsx)(n.strong,{children:"thundering herd problem"})," that overwhelms the recovering system."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Types:"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Full Jitter"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"delay = random(0, exponential_backoff)\nExample: random(0, 8s) \u2192 could be 2.3s, 5.7s, 7.1s\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Equal Jitter"})," (Recommended)"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"delay = (exponential_backoff / 2) + random(0, exponential_backoff / 2)\nExample: (8s / 2) + random(0, 4s) \u2192 between 4s and 8s\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Decorrelated Jitter"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"delay = min(cap, random(base, previous_delay * 3))\nMore aggressive randomization for high-load scenarios\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Impact:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Without jitter: 10,000 clients retry at exactly 8s \u2192 10,000 simultaneous requests"}),"\n",(0,s.jsx)(n.li,{children:"With jitter: 10,000 clients retry spread across 4s-8s \u2192 ~1,250 requests per second"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"4\ufe0f\u20e3-circuit-breaker",children:"4\ufe0f\u20e3 Circuit Breaker"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"What is it?"}),"\nA state machine that prevents requests to a failing service, allowing it to recover without being bombarded."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"States:"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Closed (Normal)"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"All requests pass through"}),"\n",(0,s.jsx)(n.li,{children:"Tracks failure rate"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Open (Service Down)"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Immediately fails requests without trying"}),"\n",(0,s.jsx)(n.li,{children:"Returns fallback response or cached data"}),"\n",(0,s.jsx)(n.li,{children:"Prevents cascading failures"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Half-Open (Testing)"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Allows limited requests to test recovery"}),"\n",(0,s.jsx)(n.li,{children:"If successful \u2192 Close circuit"}),"\n",(0,s.jsx)(n.li,{children:"If failed \u2192 Open circuit again"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Configuration Example:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Failure threshold: 50% errors in last 10 requests\nTimeout: 30 seconds (before trying Half-Open)\nSuccess threshold: 3 consecutive successes to close\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Why use it?"}),"\nProtects your system from wasting resources on a service that's clearly down, and protects the failing service from retry storms."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"5\ufe0f\u20e3-rate-limiting--throttling",children:"5\ufe0f\u20e3 Rate Limiting & Throttling"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Rate Limiting"}),"\nRestricts the number of requests a client can make in a time window."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Examples:\n- 100 requests per minute per API key\n- 10 login attempts per hour per IP\n- 1000 writes per second per database\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Throttling"}),"\nDynamically slows down requests when system is under load."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"- 429 Too Many Requests \u2192 retry after X seconds\n- Adaptive: reduce throughput based on CPU/memory\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Algorithms:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Token Bucket"}),": Refills tokens at fixed rate"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Leaky Bucket"}),": Processes requests at constant rate"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Sliding Window"}),": Counts requests in rolling time window"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Fixed Window"}),": Resets counter at fixed intervals"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"6\ufe0f\u20e3-dead-letter-queue-dlq",children:"6\ufe0f\u20e3 Dead Letter Queue (DLQ)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"What is it?"}),"\nA separate queue where messages go after all retry attempts fail."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Why use it?"}),"\nPrevents poison messages from blocking queue processing while preserving them for debugging and manual intervention."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Flow:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"1. Message processing fails\n2. Retry with backoff (3 times)\n3. Still failing \u2192 Move to DLQ\n4. Alert engineers\n5. Manual inspection and reprocessing\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Monitor DLQ depth"}),"\n",(0,s.jsx)(n.li,{children:"Set up alerts for DLQ messages"}),"\n",(0,s.jsx)(n.li,{children:"Implement DLQ replay mechanisms"}),"\n",(0,s.jsx)(n.li,{children:"Analyze patterns in failed messages"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"-real-world-example-payment-processing-system",children:"\ud83c\udfaf Real-World Example: Payment Processing System"}),"\n",(0,s.jsx)(n.h3,{id:"scenario",children:"Scenario"}),"\n",(0,s.jsxs)(n.p,{children:["A ",(0,s.jsx)(n.strong,{children:"Payment Service"})," needs to process a transaction by calling an external ",(0,s.jsx)(n.strong,{children:"Payment Gateway API"})," (Stripe, PayPal, etc.)"]}),"\n",(0,s.jsx)(n.h3,{id:"architecture",children:"Architecture"}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TB\n    User[User Checkout]\n    PS[Payment Service]\n    RC[Retry Controller]\n    CB[Circuit Breaker]\n    PG[Payment Gateway API]\n    DB[(Database)]\n    DLQ[Dead Letter Queue]\n    Cache[(Cache)]\n\n    User --\x3e|1. Pay $100| PS\n    PS --\x3e|2. Check Circuit| CB\n    CB --\x3e|3. Closed? Proceed| RC\n    RC --\x3e|4. Attempt Payment| PG\n    PG --\x3e|5. Timeout/503| RC\n    RC --\x3e|6. Retry with Backoff+Jitter| PG\n    PG --\x3e|7. Still Failing| RC\n    RC --\x3e|8. Update Failure Count| CB\n    CB --\x3e|9. Open Circuit| PS\n    PS --\x3e|10. Return Cached Response| Cache\n    PS --\x3e|11. Failed After Retries| DLQ\n    PS --\x3e|12. Store Transaction| DB\n\n    style CB fill:#ff6b6b\n    style RC fill:#4ecdc4\n    style DLQ fill:#ffe66d\n    style PG fill:#95e1d3"}),"\n",(0,s.jsx)(n.h3,{id:"step-by-step-flow",children:"Step-by-Step Flow"}),"\n",(0,s.jsx)(n.h4,{id:"step-1-initial-request",children:(0,s.jsx)(n.strong,{children:"Step 1: Initial Request"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'User initiates $100 payment\nPayment Service generates idempotency key: "payment_abc123"\n'})}),"\n",(0,s.jsx)(n.h4,{id:"step-2-circuit-breaker-check",children:(0,s.jsx)(n.strong,{children:"Step 2: Circuit Breaker Check"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Circuit Breaker State: CLOSED (service is healthy)\n\u2705 Allow request to proceed\n"})}),"\n",(0,s.jsx)(n.h4,{id:"step-3-first-attempt",children:(0,s.jsx)(n.strong,{children:"Step 3: First Attempt"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"POST /charge\nHeaders: {\n  Idempotency-Key: payment_abc123,\n  Amount: 10000 (cents)\n}\n\nResponse: 503 Service Unavailable (Gateway overloaded)\n"})}),"\n",(0,s.jsx)(n.h4,{id:"step-4-retry-logic-kicks-in",children:(0,s.jsx)(n.strong,{children:"Step 4: Retry Logic Kicks In"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Attempt 1:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Base delay: 1 second\nExponential: 2^0 = 1s\nJitter: random(0.5s, 1.5s) = 0.8s\nWait: 0.8s\nResult: Timeout \u274c\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Attempt 2:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Exponential: 2^1 = 2s\nJitter: random(1s, 3s) = 2.3s\nWait: 2.3s\nResult: 502 Bad Gateway \u274c\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Attempt 3:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Exponential: 2^2 = 4s\nJitter: random(2s, 6s) = 4.7s\nWait: 4.7s\nResult: 200 OK \u2705\nIdempotency key prevents duplicate charge\n"})}),"\n",(0,s.jsx)(n.h4,{id:"step-5-success-response",children:(0,s.jsx)(n.strong,{children:"Step 5: Success Response"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Payment processed successfully\nCircuit breaker records success\nUser receives confirmation\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"what-if-all-retries-failed",children:"What If All Retries Failed?"}),"\n",(0,s.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant PS as Payment Service\n    participant RC as Retry Controller\n    participant CB as Circuit Breaker\n    participant PG as Payment Gateway\n    participant DLQ as Dead Letter Queue\n    participant Alert as Alert System\n\n    PS->>CB: Check Circuit State\n    CB->>PS: CLOSED (OK to try)\n    PS->>RC: Process Payment\n    RC->>PG: Attempt 1\n    PG--\x3e>RC: 503 Error\n    Note over RC: Wait 1s (with jitter)\n    RC->>PG: Attempt 2\n    PG--\x3e>RC: Timeout\n    Note over RC: Wait 2s (with jitter)\n    RC->>PG: Attempt 3\n    PG--\x3e>RC: 502 Error\n    Note over RC: Wait 4s (with jitter)\n    RC->>PG: Attempt 4\n    PG--\x3e>RC: 503 Error\n    RC->>CB: Report 4 Failures\n    CB->>CB: Threshold Exceeded\n    CB->>CB: State = OPEN\n    RC->>DLQ: Send Failed Payment\n    DLQ->>Alert: Trigger Alert\n    PS->>PS: Return Cached Fallback\n    PS--\x3e>User: Payment Pending, Will Retry"}),"\n",(0,s.jsx)(n.h4,{id:"outcome",children:(0,s.jsx)(n.strong,{children:"Outcome:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Circuit breaker opens after failure threshold"}),"\n",(0,s.jsx)(n.li,{children:"Failed payment goes to DLQ"}),"\n",(0,s.jsx)(n.li,{children:'User gets friendly error: "Payment processing delayed, you won\'t be charged twice"'}),"\n",(0,s.jsx)(n.li,{children:"Engineers notified to investigate"}),"\n",(0,s.jsx)(n.li,{children:"Next requests fail fast (circuit open) instead of waiting for timeouts"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"-configuration-examples",children:"\ud83d\udcca Configuration Examples"}),"\n",(0,s.jsx)(n.h3,{id:"retry-policy",children:"Retry Policy"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'retry_config = {\n    "max_attempts": 4,\n    "base_delay": 1.0,  # seconds\n    "max_delay": 30.0,\n    "exponential_base": 2,\n    "jitter": "equal",\n    "retryable_errors": [\n        "TimeoutError",\n        "ConnectionError",\n        "503",\n        "502",\n        "429"\n    ],\n    "idempotency_required": True\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"circuit-breaker-config",children:"Circuit Breaker Config"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"circuit_breaker:\n  failure_threshold: 5 # failures to open\n  failure_rate: 50 # % failures in window\n  window_size: 10 # requests to track\n  timeout: 30 # seconds before half-open\n  half_open_requests: 3 # test requests\n  success_threshold: 2 # successes to close\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"-interview-talking-points",children:"\ud83c\udfa4 Interview Talking Points"}),"\n",(0,s.jsxs)(n.p,{children:["When discussing resilience patterns in ",(0,s.jsx)(n.strong,{children:"system design interviews"}),", demonstrate depth by covering:"]}),"\n",(0,s.jsxs)(n.h3,{id:"1-why-retries-alone-are-dangerous",children:["1. ",(0,s.jsx)(n.strong,{children:"Why Retries Alone Are Dangerous"})]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:'"Retries without backoff can create a retry storm where thousands of clients hammer a recovering service, making the problem worse. This is called the thundering herd problem."'}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"2-retry--backoff--jitter--best-practice",children:["2. ",(0,s.jsx)(n.strong,{children:"Retry + Backoff + Jitter = Best Practice"})]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:'"I\'d implement exponential backoff with equal jitter. This spreads retries over time and prevents synchronized stampedes. For example, with jitter, 10,000 clients retrying at 8s becomes a smooth distribution between 4-8 seconds."'}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"3-circuit-breakers-for-cascading-failure-prevention",children:["3. ",(0,s.jsx)(n.strong,{children:"Circuit Breakers for Cascading Failure Prevention"})]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:'"If the payment gateway is down, a circuit breaker prevents our service from wasting threads waiting for timeouts. It fails fast and returns cached responses, protecting both our system and theirs."'}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"4-idempotency-is-critical",children:["4. ",(0,s.jsx)(n.strong,{children:"Idempotency is Critical"})]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"\"For payment processing, I'd use idempotency keys so retries don't double-charge customers. The same key ensures the gateway processes the request exactly once, even if we retry.\""}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"5-observability-matters",children:["5. ",(0,s.jsx)(n.strong,{children:"Observability Matters"})]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:'"I\'d emit metrics for retry counts, circuit breaker state changes, and DLQ depth. Alerts on high retry rates or circuit breaker trips help us detect issues before they cascade."'}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"6-dead-letter-queues-for-async-systems",children:["6. ",(0,s.jsx)(n.strong,{children:"Dead Letter Queues for Async Systems"})]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:'"For async payment processing with Kafka or SQS, failed messages after all retries go to a DLQ. This preserves data for debugging while preventing poison messages from blocking the queue."'}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"-quick-formula-for-interviews",children:"\u26a1 Quick Formula for Interviews"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Retry                          = Good (fixes transient issues)\nRetry + Backoff                = Better (prevents overwhelming system)\nRetry + Backoff + Jitter       = Best (prevents thundering herd)\n+ Circuit Breaker              = Production-ready (prevents cascading failures)\n+ Idempotency + DLQ + Metrics  = Enterprise-grade (robust & observable)\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"-common-interview-questions",children:"\ud83d\udd0d Common Interview Questions"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Q: When should you NOT retry?"}),"\nA: Don't retry on 4xx errors (except 408, 429), authentication failures, or validation errors. These are client errors that won't resolve with retries."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Q: How do you prevent duplicate payments?"}),"\nA: Use idempotency keys. Generate a unique key per payment request and send it with every retry. The payment gateway deduplicates using this key."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Q: What's the difference between circuit breaker and retry?"}),"\nA: Retries handle individual request failures. Circuit breakers handle systemic failures by stopping all requests when a service is clearly down, preventing resource exhaustion."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Q: How would you handle a third-party API with rate limiting?"}),"\nA: Implement token bucket rate limiting on our side, respect 429 Retry-After headers, use exponential backoff with jitter for 429 responses, and consider request queuing with priority."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"\ufe0f-implementation-considerations",children:"\ud83d\udee0\ufe0f Implementation Considerations"}),"\n",(0,s.jsx)(n.h3,{id:"choose-your-strategy-based-on",children:"Choose Your Strategy Based On:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Low-Latency Requirements (< 100ms)"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Fewer retries (2-3 max)"}),"\n",(0,s.jsx)(n.li,{children:"Shorter backoff (100ms, 200ms, 400ms)"}),"\n",(0,s.jsx)(n.li,{children:"Aggressive circuit breaker (fail fast)"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"High-Reliability Requirements (payments, orders)"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"More retries (4-5)"}),"\n",(0,s.jsx)(n.li,{children:"Longer backoff (1s, 2s, 4s, 8s)"}),"\n",(0,s.jsx)(n.li,{children:"Conservative circuit breaker"}),"\n",(0,s.jsx)(n.li,{children:"DLQ for all failures"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Real-Time Systems (streaming, gaming)"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Minimal retries (1-2)"}),"\n",(0,s.jsx)(n.li,{children:"Fallback to cached data immediately"}),"\n",(0,s.jsx)(n.li,{children:"Fast circuit breaker trip"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Batch Processing"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"More aggressive retries (5-10)"}),"\n",(0,s.jsx)(n.li,{children:"Exponential backoff with cap"}),"\n",(0,s.jsx)(n.li,{children:"DLQ for permanent failures"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"-monitoring--alerts",children:"\ud83d\udcc8 Monitoring & Alerts"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Key Metrics:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Retry rate per service"}),"\n",(0,s.jsx)(n.li,{children:"Average retry attempts per request"}),"\n",(0,s.jsx)(n.li,{children:"Circuit breaker state (open/closed/half-open)"}),"\n",(0,s.jsx)(n.li,{children:"DLQ depth and age of messages"}),"\n",(0,s.jsx)(n.li,{children:"Request latency (including retry delays)"}),"\n",(0,s.jsx)(n.li,{children:"Success rate after retries"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Critical Alerts:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Circuit breaker opened"}),"\n",(0,s.jsx)(n.li,{children:"Retry rate > 20%"}),"\n",(0,s.jsx)(n.li,{children:"DLQ depth > threshold"}),"\n",(0,s.jsx)(n.li,{children:"Retry storm detected (many simultaneous retries)"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"-summary",children:"\ud83c\udfaf Summary"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Pattern"}),(0,s.jsx)(n.th,{children:"Purpose"}),(0,s.jsx)(n.th,{children:"When to Use"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Retry"})}),(0,s.jsx)(n.td,{children:"Handle transient failures"}),(0,s.jsx)(n.td,{children:"Network glitches, temporary overload"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Backoff"})}),(0,s.jsx)(n.td,{children:"Space out retries"}),(0,s.jsx)(n.td,{children:"Prevent overwhelming recovering systems"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Jitter"})}),(0,s.jsx)(n.td,{children:"Randomize retry timing"}),(0,s.jsx)(n.td,{children:"Prevent thundering herd with many clients"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Circuit Breaker"})}),(0,s.jsx)(n.td,{children:"Stop requests to failing service"}),(0,s.jsx)(n.td,{children:"Systemic failures, cascading prevention"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Rate Limiting"})}),(0,s.jsx)(n.td,{children:"Control request volume"}),(0,s.jsx)(n.td,{children:"Protect APIs, prevent abuse"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"DLQ"})}),(0,s.jsx)(n.td,{children:"Preserve failed messages"}),(0,s.jsx)(n.td,{children:"Async systems, debugging, reprocessing"})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Golden Rule"}),": Always combine retry + exponential backoff + jitter for distributed systems. Add circuit breakers for critical dependencies. Implement idempotency for state-changing operations."]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);