# Caching Patterns in System Design

## ðŸ“š Core Concepts

### Cache Hit vs Cache Miss

| Term              | Definition                    | Speed    | What Happens                                           |
| ----------------- | ----------------------------- | -------- | ------------------------------------------------------ |
| **Cache Hit** âœ…  | Requested data found in cache | **Fast** | Data retrieved directly from cache                     |
| **Cache Miss** âŒ | Requested data not in cache   | **Slow** | Must fetch from main storage, then optionally cache it |

#### Analogy

Think of cache as your **desk drawer** and main memory as a **library shelf**:

- **Cache hit**: Find your notebook in the desk drawer â†’ instant access âš¡
- **Cache miss**: Not in drawer â†’ walk to library shelf â†’ slower retrieval ðŸŒ

---

## ðŸ”„ Caching Patterns

### 1. Cache-Aside (Lazy Loading)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
  Check Cache?
   â”œâ”€ Hit â†’ Return
   â””â”€ Miss â†’ Fetch DB â†’ Store in Cache â†’ Return
```

**Characteristics:**

- Application manages cache explicitly
- Cache populated on-demand
- Most common pattern

**Pros:**

- âœ… Only caches what's actually needed
- âœ… Cache failure doesn't break the system
- âœ… Flexible - app has full control

**Cons:**

- âŒ First request always slow (cache miss)
- âŒ Extra code in application layer
- âŒ Potential for stale data

**When to Use:**

- Read-heavy workloads
- When you want fine-grained control
- General-purpose caching (Redis, Memcached)

**Real-World Example:** E-commerce product catalog caching

---

### 2. Read-Through

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application â”‚ â”€â”€Readâ”€â”€> â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ Cache â”‚ â”€â”€Auto Fetchâ”€â”€> Database
                          â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Characteristics:**

- Cache layer handles data loading
- Transparent to application
- Cache acts as abstraction over DB

**Pros:**

- âœ… Simpler application code
- âœ… Centralized cache logic
- âœ… Consistent read interface

**Cons:**

- âŒ First request still slow
- âŒ Adds complexity to cache layer
- âŒ Tighter coupling with cache system

**When to Use:**

- When you want cache to own data loading
- Frameworks that support it (Ehcache, Caffeine)
- Microservices with dedicated cache service

**Difference from Cache-Aside:** Cache handles DB fetch vs application handles it

---

### 3. Write-Through

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application â”‚ â”€â”€Writeâ”€â”€â”¬â”€â”€> Cache (sync)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€> Database (sync)
```

**Characteristics:**

- Every write goes to both cache and DB
- Synchronous double-write
- Strong consistency guaranteed

**Pros:**

- âœ… Cache always fresh and consistent
- âœ… No risk of stale reads
- âœ… Simple consistency model

**Cons:**

- âŒ Higher write latency (two operations)
- âŒ Wasted writes for rarely-read data
- âŒ Cache can fill with cold data

**When to Use:**

- Strong consistency requirements
- Read-after-write scenarios common
- Financial systems, user profiles

**Real-World Example:** User session data, account balances

---

### 4. Write-Behind / Write-Back

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application â”‚ â”€â”€Writeâ”€â”€> Cache (fast return) ~~async batch~~> Database
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Characteristics:**

- Writes happen to cache only
- DB updated later in batches
- Eventually consistent

**Pros:**

- âœ… Extremely fast writes
- âœ… Can batch/coalesce multiple writes
- âœ… Reduces DB load significantly

**Cons:**

- âŒ Risk of data loss if cache fails
- âŒ Complexity in failure handling
- âŒ Eventual consistency only

**When to Use:**

- High write throughput needed
- Acceptable to lose recent writes on failure
- Analytics pipelines, logging systems

**Real-World Example:** Page view counters, metrics aggregation

---

### 5. Write-Around

```
Write: Application â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Database (bypass cache)
Read:  Application â”€â”€> Cache? â”€â”€Missâ”€â”€> Database â”€â”€> Cache
```

**Characteristics:**

- Writes skip the cache entirely
- Cache populated only on reads
- Prevents cache pollution

**Pros:**

- âœ… Avoids caching rarely-read data
- âœ… Keeps cache focused on hot data
- âœ… Better cache hit ratio for actual reads

**Cons:**

- âŒ First read after write always misses
- âŒ Higher latency for read-after-write
- âŒ Not ideal for write-then-read patterns

**When to Use:**

- High write volume, low read volume
- Write-once-read-never scenarios
- Log ingestion, data warehousing

**Real-World Example:** Event logging, audit trails

---

### 6. Refresh-Ahead (Proactive Caching)

```
Cache monitors TTL â”€â”€> Preemptively refreshes BEFORE expiration
```

**Characteristics:**

- Predictive cache warming
- Reduces cache misses for hot data
- Requires usage pattern prediction

**Pros:**

- âœ… Minimizes cache misses
- âœ… Consistent low latency
- âœ… Great for predictable access patterns

**Cons:**

- âŒ Wastes resources on cold data
- âŒ Complex implementation
- âŒ Needs good prediction algorithm

**When to Use:**

- Frequently accessed data with predictable patterns
- Low-latency requirements (gaming, trading)
- Content delivery networks (CDN)

**Real-World Example:** Homepage content, trending articles

---

### 7. TTL (Time-to-Live) Based

```
Cache Entry [Created] â”€â”€(time passes)â”€â”€> [TTL Expires] â”€â”€> Auto-removed
```

**Characteristics:**

- Time-based expiration
- Simplest invalidation strategy
- Combined with other patterns

**Pros:**

- âœ… Simple to implement
- âœ… Prevents indefinitely stale data
- âœ… Works with any caching pattern

**Cons:**

- âŒ Can cause cache miss storms at expiration
- âŒ Arbitrary time selection
- âŒ May evict still-valid data

**When to Use:**

- Data with known freshness requirements
- Combined with most caching strategies
- Session tokens, temporary data

**Real-World Example:** API rate limiting, JWT tokens

---

## ðŸ—‘ï¸ Eviction Policies

### LRU (Least Recently Used)

- **Strategy:** Evicts items not accessed recently
- **Best for:** Temporal locality (recently used = likely to be used again)
- **Example:** Web page caching

### LFU (Least Frequently Used)

- **Strategy:** Evicts items accessed least often
- **Best for:** Popular content, frequency-based access
- **Example:** Video streaming platforms

### FIFO (First In First Out)

- **Strategy:** Evicts oldest entries
- **Best for:** Simple queue-like behavior
- **Example:** Basic message queues

### Random Replacement

- **Strategy:** Evicts random entries
- **Best for:** When no clear pattern exists, lowest overhead
- **Example:** Simple distributed caches

---

## ðŸ“Š Pattern Comparison Matrix

| Pattern           | Write Speed  | Read Speed   | Consistency | Complexity | Data Loss Risk |
| ----------------- | ------------ | ------------ | ----------- | ---------- | -------------- |
| **Cache-Aside**   | ðŸŸ¡ Medium    | ðŸŸ¢ Fast\*    | ðŸŸ¡ Eventual | ðŸŸ¢ Low     | ðŸŸ¢ Low         |
| **Read-Through**  | ðŸŸ¡ Medium    | ðŸŸ¢ Fast\*    | ðŸŸ¡ Eventual | ðŸŸ¡ Medium  | ðŸŸ¢ Low         |
| **Write-Through** | ðŸ”´ Slow      | ðŸŸ¢ Very Fast | ðŸŸ¢ Strong   | ðŸŸ¢ Low     | ðŸŸ¢ None        |
| **Write-Back**    | ðŸŸ¢ Very Fast | ðŸŸ¢ Very Fast | ðŸŸ¡ Eventual | ðŸ”´ High    | ðŸ”´ High        |
| **Write-Around**  | ðŸŸ¢ Fast      | ðŸŸ¡ Medium    | ðŸŸ¡ Eventual | ðŸŸ¢ Low     | ðŸŸ¢ None        |
| **Refresh-Ahead** | ðŸŸ¡ Medium    | ðŸŸ¢ Very Fast | ðŸŸ¡ Eventual | ðŸ”´ High    | ðŸŸ¢ Low         |

\*After initial cache miss

---

## ðŸŽ¯ Common Pattern Combinations

### High-Traffic Web Application

```yaml
Read Strategy: Cache-Aside + LRU eviction
Write Strategy: Write-Through for critical data
TTL: 5-15 minutes for most content
Tools: Redis, Memcached
```

### Analytics Pipeline

```yaml
Read Strategy: Read-Through
Write Strategy: Write-Back (batch inserts)
Eviction: LFU (frequently queried reports)
Tools: Apache Ignite, Hazelcast
```

### E-commerce Product Catalog

```yaml
Read Strategy: Cache-Aside + Refresh-Ahead for bestsellers
Write Strategy: Write-Around for inventory updates
TTL: 1 hour for product details
Tools: Redis with pub/sub for invalidation
```

### Social Media Feed

```yaml
Read Strategy: Cache-Aside + Refresh-Ahead for active users
Write Strategy: Write-Back for likes/views
TTL: 30 seconds for feed items
Eviction: LRU
Tools: Redis Cluster
```

---

## ðŸŒ³ Decision Tree

```
â”Œâ”€ Need strong consistency?
â”‚   â”œâ”€ YES â†’ Write-Through
â”‚   â””â”€ NO â†“
â”‚
â”œâ”€ High write volume?
â”‚   â”œâ”€ YES â†“
â”‚   â”‚   â”œâ”€ Can tolerate data loss?
â”‚   â”‚   â”‚   â”œâ”€ YES â†’ Write-Back
â”‚   â”‚   â”‚   â””â”€ NO â†’ Write-Around
â”‚   â””â”€ NO â†’ Cache-Aside
â”‚
â”œâ”€ Need ultra-low read latency?
â”‚   â””â”€ Add Refresh-Ahead
â”‚
â””â”€ Cache filling up?
    â””â”€ Choose eviction:
        â”œâ”€ Temporal patterns â†’ LRU
        â””â”€ Popularity-based â†’ LFU
```

---

## âœ… Best Practices

1. **Start with Cache-Aside**
   - Most flexible and widely understood
   - Easy to debug and reason about

2. **Always Set TTL**
   - Even with other invalidation strategies
   - Prevents unbounded cache growth

3. **Monitor Cache Hit Ratio**
   - Aim for >80% for effectiveness
   - Alert on sudden drops

4. **Handle Cache Failures Gracefully**
   - App should work even if cache is down
   - Implement circuit breakers

5. **Use Appropriate Serialization**
   - Consider Protobuf/MessagePack over JSON
   - Faster and more compact

6. **Warm Critical Caches on Startup**
   - Don't wait for cold starts
   - Pre-populate frequently accessed data

7. **Implement Cache Stampede Protection**
   - Use locks/semaphores for cache misses
   - Prevent thundering herd

8. **Size Your Cache Appropriately**
   - Monitor eviction rates
   - Balance memory cost vs hit rate

---

## âš¡ Performance Tips

- **Batch operations** when possible (especially with Write-Back)
- **Use pipeline/multi-get** for multiple keys (Redis MGET, MSET)
- **Consider cache-aside for writes** even with read-through for reads
- **Implement circuit breakers** for cache failures
- **Use connection pooling** for cache clients
- **Monitor P99 latencies**, not just averages
- **Compress large values** before caching
- **Use appropriate data structures** (Redis Hashes, Sets, Sorted Sets)

---

## âš ï¸ Common Pitfalls

### âŒ Cache Stampede

**Problem:** Multiple requests reload same expired data simultaneously

**Solution:**

- Locking mechanisms (distributed locks)
- Early recomputation (refresh before expiry)
- Probabilistic early expiration

### âŒ Stale Data

**Problem:** Cache inconsistent with database

**Solution:**

- Proper TTL settings
- Invalidation on writes
- Event-driven cache updates

### âŒ Cache Pollution

**Problem:** Rarely-used data fills cache

**Solution:**

- Write-Around pattern
- Better eviction policies (LRU/LFU)
- Cache only frequently accessed data

### âŒ Over-caching

**Problem:** Caching everything indiscriminately

**Solution:**

- Profile and measure what to cache
- Cache only expensive queries
- Monitor cache hit rates per key pattern

### âŒ No Monitoring

**Problem:** Not knowing hit rates, evictions, or issues

**Solution:**

- Implement comprehensive metrics
- Dashboard for cache health
- Alerts for anomalies

### âŒ Ignoring Cache Warm-up

**Problem:** Cold start causes poor initial performance

**Solution:**

- Pre-populate cache on deployment
- Gradual traffic ramping
- Keep cache instances alive during deployments

---

## ðŸ“ˆ Key Metrics to Monitor

| Metric                 | What It Measures                 | Target                |
| ---------------------- | -------------------------------- | --------------------- |
| **Hit Rate**           | % of requests served from cache  | >80%                  |
| **Miss Rate**          | % of requests requiring DB fetch | `<20%`                |
| **Eviction Rate**      | How often data is removed        | Low & stable          |
| **Memory Usage**       | Cache memory consumption         | `<80%` capacity       |
| **Latency (P50, P99)** | Response time distribution       | `<10ms` P99           |
| **Throughput**         | Operations per second            | Application dependent |
| **Connection Pool**    | Active connections               | Stable                |
| **Error Rate**         | Failed cache operations          | `<0.1%`               |

---

## ðŸ› ï¸ Popular Cache Technologies

### In-Memory Caches

- **Redis** - Feature-rich, supports data structures, persistence
- **Memcached** - Simple, fast, lightweight
- **Hazelcast** - Distributed, Java-based, compute capabilities

### Application-Level Caches

- **Caffeine** - High-performance Java cache library
- **Ehcache** - Java cache with disk persistence
- **Guava Cache** - Simple in-process cache for Java

### CDN/Edge Caches

- **CloudFlare** - Global CDN with edge caching
- **AWS CloudFront** - Integrated with AWS services
- **Fastly** - Real-time CDN with VCL customization

### Distributed Caches

- **Apache Ignite** - Distributed database and cache
- **Aerospike** - High-performance distributed cache
- **Couchbase** - Document DB with built-in caching

---

## ðŸ“š Further Reading

- **Redis Documentation**: https://redis.io/docs/
- **Memcached Wiki**: https://github.com/memcached/memcached/wiki
- **AWS Caching Best Practices**: https://aws.amazon.com/caching/
- **Martin Fowler on Caching**: https://martinfowler.com/
- **Google SRE Book - Caching**: https://sre.google/sre-book/
- **Designing Data-Intensive Applications** by Martin Kleppmann (Chapter 3)

---

## ðŸŽ“ Quick Reference Cheat Sheet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WHEN TO USE WHICH PATTERN                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Read-Heavy + Control      â†’ Cache-Aside         â”‚
â”‚ Strong Consistency        â†’ Write-Through       â”‚
â”‚ High Write Throughput     â†’ Write-Back          â”‚
â”‚ Rarely Read After Write   â†’ Write-Around        â”‚
â”‚ Predictable Hot Data      â†’ Refresh-Ahead       â”‚
â”‚ Time-Sensitive Data       â†’ TTL-Based           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EVICTION POLICY SELECTION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recent = Relevant         â†’ LRU                 â”‚
â”‚ Frequency Matters         â†’ LFU                 â”‚
â”‚ Simple Queue              â†’ FIFO                â”‚
â”‚ No Pattern / Testing      â†’ Random              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---
